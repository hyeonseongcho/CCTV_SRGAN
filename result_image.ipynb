{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/leftthomas/SRGAN\n",
    "\n",
    "import os\n",
    "from math import log10\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# import pytorch_ssim\n",
    "import data_utils\n",
    "from data_utils import CustumDataset, display_transform\n",
    "from loss import GeneratorLoss\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "high_res = 128\n",
    "upscale_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(A, B):\n",
    "    \n",
    "    pil_A = pil_transform(A[0])\n",
    "    gray_A = cv2.cvtColor(np.array(pil_A), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    pil_B = pil_transform(B[0])\n",
    "    gray_B = cv2.cvtColor(np.array(pil_B), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    score, diff = compare_ssim(gray_A, gray_B, full=True)\n",
    "    diff = (diff * 255).astype('uint8')\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustumDataset('data/valid/test', high_res, upscale_factor)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "netG = Generator(upscale_factor).cuda()\n",
    "netD = Discriminator().cuda()\n",
    "\n",
    "generator_criterion = GeneratorLoss().cuda()\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())\n",
    "\n",
    "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
    "\n",
    "checkpoint = torch.load(f'./res{high_res}_uf{upscale_factor}.tar')\n",
    "\n",
    "netG.load_state_dict(checkpoint['G_model_state_dict'])\n",
    "netD.load_state_dict(checkpoint['D_model_state_dict'])\n",
    "optimizerG.load_state_dict(checkpoint['G_optimizer_state_dict'])\n",
    "optimizerD.load_state_dict(checkpoint['D_optimizer_state_dict'])\n",
    "\n",
    "g_loss = checkpoint['G_loss']\n",
    "d_loss = checkpoint['D_loss']\n",
    "\n",
    "netG.eval()\n",
    "netD.eval()\n",
    "\n",
    "upsample_nearest = torch.nn.Upsample(scale_factor=upscale_factor, mode='nearest').cuda()\n",
    "upsample_bilinear = torch.nn.Upsample(scale_factor=upscale_factor, mode='bilinear').cuda()\n",
    "\n",
    "pil_transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToPILImage(),\n",
    "                            ])\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f'results/res_{high_res}_srf_{upscale_factor}/'\n",
    "images = []\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for lr, hr in test_loader:\n",
    "        batch_size = lr.size(0)\n",
    "        results = {'mse': 0, 'ssim': 0, 'psnr': 0}\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            lr = lr.cuda()\n",
    "            hr = hr.cuda()\n",
    "\n",
    "        sr = netG(lr)\n",
    "\n",
    "        lr_upsample = upsample_nearest(lr)\n",
    "        lr_bilinear = upsample_bilinear(lr)\n",
    "\n",
    "        \n",
    "        images.extend([display_transform()(lr_upsample.data.cpu().squeeze(0)),\n",
    "                        display_transform()(lr_bilinear.data.cpu().squeeze(0)),\n",
    "                        display_transform()(sr.data.cpu().squeeze(0)),\n",
    "                        display_transform()(hr.data.cpu().squeeze(0))])\n",
    "\n",
    "        mse_sr = ((sr - hr) ** 2).data.mean()\n",
    "        psnr_sr = 10 * log10((hr.max()**2) / mse_sr)\n",
    "        ssim_sr = compute_ssim(sr, hr)\n",
    "\n",
    "        mse_lr = ((lr_upsample - hr) ** 2).data.mean()\n",
    "        psnr_lr = 10 * log10((hr.max()**2) / mse_lr)\n",
    "        ssim_lr = compute_ssim(lr_upsample, hr)\n",
    "\n",
    "        mse_bl = ((lr_bilinear - hr) ** 2).data.mean()\n",
    "        psnr_bl = 10 * log10((hr.max()**2) / mse_bl)\n",
    "        ssim_bl = compute_ssim(lr_bilinear, hr)\n",
    "\n",
    "        print('----------------------')\n",
    "        print(mse_lr, psnr_lr, ssim_lr)\n",
    "        print(mse_bl, psnr_bl, ssim_bl)\n",
    "        print(mse_sr, psnr_sr, ssim_sr)\n",
    "\n",
    "images = torch.stack(images)\n",
    "print(images.size())\n",
    "saving_image = utils.make_grid(images, nrow=4, padding=10)\n",
    "utils.save_image(saving_image, out_path + 'result.png', padding=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('CHO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75e71d7c28e93eec18ce6910883a2a9a22f0497d07a96546cfcbe0a235c3f893"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
